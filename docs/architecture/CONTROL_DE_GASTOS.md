# ğŸ”’ CONTROL DE GASTOS - MODELOS PAGOS DISPONIBLES PERO DESHABILITADOS

## ğŸ“‹ CÃ“MO FUNCIONA

### Concepto:
Puedes **configurar las API keys** de modelos pagos (Claude, GPT-4), pero **NO se usarÃ¡n automÃ¡ticamente**.

### Estado por defecto:
- ğŸ†“ **Gemini** â†’ âœ… SIEMPRE HABILITADO (gratis)
- âš ï¸ **Claude** â†’ ğŸ”’ BLOQUEADO (configuras key pero no se usa)
- ğŸ’° **GPT-4** â†’ ğŸ”’ BLOQUEADO (configuras key pero no se usa)

### CuÃ¡ndo activar modelos pagos:
Solo cuando **tÃº decidas conscientemente gastar dinero**.

---

## ğŸ› ï¸ COMANDOS DE CONTROL

### Ver estado actual:
```powershell
cd c:\BioEngine_V3
python backend/services/cost_control.py status
```

**Salida esperada:**
```
ğŸ“Š ESTADO DE MODELOS:

ğŸ†“ Modelos Gratuitos:
  â€¢ gemini: 50 usos

ğŸ’° Modelos Pagos:
  ğŸ”’ anthropic: 0 usos, $0.0000
  ğŸ”’ openai: 0 usos, $0.0000

ğŸ’µ Costo total estimado: $0.0000
```

### Habilitar modelos pagos temporalmente:
```powershell
# Por 60 minutos (default)
python backend/services/cost_control.py enable

# Por 30 minutos
python backend/services/cost_control.py enable 30

# Por 2 horas (120 min)
python backend/services/cost_control.py enable 120
```

**Salida:**
```
âœ… Modelos pagos habilitados por 60 minutos (mÃ¡x $1.0)
â° Se deshabilitarÃ¡n automÃ¡ticamente despuÃ©s
```

### Deshabilitar modelos pagos:
```powershell
python backend/services/cost_control.py disable
```

**Salida:**
```
ğŸ”’ Modelos pagos deshabilitados. Solo se usarÃ¡n modelos gratuitos.
```

---

## ğŸ¯ CASOS DE USO

### Caso 1: Uso normal (Solo Gemini gratis)
```
1. Usuario escribe mensaje
2. Sistema usa Gemini 2.0 (gratis)
3. Si falla â†’ Gemini 1.5 (gratis)
4. Si ambos fallan â†’ Error (no intenta modelos pagos)
```

### Caso 2: Gemini no funciona + Necesitas respuesta urgente
```bash
# Habilitas modelos pagos por 30 minutos
python backend/services/cost_control.py enable 30
```

```
1. Usuario escribe mensaje
2. Sistema intenta Gemini 2.0 â†’ Falla
3. Sistema intenta Gemini 1.5 â†’ Falla
4. Sistema intenta Claude 3.5 (ahora permitido)
   ğŸ’° ADVERTENCIA: Usando Claude - Genera costos
5. Funciona â†’ Respuesta generada
6. DespuÃ©s de 30 min â†’ Claude se bloquea automÃ¡ticamente
```

### Caso 3: Quieres probar GPT-4 especÃ­ficamente
```bash
# Habilitas modelos pagos
python backend/services/cost_control.py enable 15

# Forzas error en Gemini (desconectas internet temporalmente)
# El sistema pasa a Claude â†’ GPT-4
```

---

## ğŸ“Š TABLA DE CONFIGURACIÃ“N (DB)

La tabla `model_cost_config` controla todo:

| provider | cost_type | allow_usage | Significado |
|----------|-----------|-------------|-------------|
| gemini | free | 2 | Siempre permitido |
| anthropic | free_tier | 0 | ğŸ”’ Bloqueado |
| openai | paid | 0 | ğŸ”’ Bloqueado |

**Valores de `allow_usage`:**
- **0**: ğŸ”’ BLOQUEADO - No se usarÃ¡ aunque tenga API key
- **1**: â° TEMPORAL - Permitido temporalmente (por X minutos)
- **2**: âœ… SIEMPRE - Siempre permitido (solo para modelos gratuitos)

---

## ğŸ”— INTEGRACIÃ“N CON MultiModelClient

Cuando `MultiModelClient.generate()` se ejecuta:

```python
for model in fallback_order:
    provider = model["provider"]
    
    # 1. Verificar si tiene API key
    if not has_api_key(provider):
        skip()
    
    # 2. Verificar si estÃ¡ permitido por CostControl
    if not cost_control.is_provider_allowed(provider):
        skip()  # ğŸ”’ BLOQUEADO
    
    # 3. Intentar usar el modelo
    try:
        response = call_model()
        return response
    except:
        continue
```

**Resultado:**
- Si `allow_usage=0` para `openai` â†’ GPT-4 se saltea aunque tengas API key
- Si `allow_usage=1` â†’ Se permite usar temporalmente
- Si `allow_usage=2` â†’ Siempre se usa (caso de Gemini)

---

## ğŸ’¡ VENTAJAS DEL SISTEMA

### âœ… Tienes las keys configuradas
- No necesitas buscarlas cuando las necesites
- EstÃ¡n listas para usar en emergencias

### âœ… Pero no gastas por error
- Por defecto BLOQUEADOS
- Requiere acciÃ³n consciente para activar

### âœ… Control temporal
- Activas por 30-60 minutos
- Se desactivan automÃ¡ticamente

### âœ… Transparencia total
- Log registra cada uso
- Sabes exactamente cuÃ¡ndo se usa un modelo pago

---

## ğŸš€ SETUP COMPLETO

### 1. Configurar todas las API keys:
```powershell
python scripts\setup_multi_model.py
```

El script te pedirÃ¡:
- âœ… Gemini (gratis) - YA CONFIGURADO
- âš ï¸ Claude (free tier â†’ paga) - OPCIONAL
- ğŸ’° OpenAI GPT-4 (paga) - OPCIONAL, con advertencia clara

### 2. Verificar estado:
```powershell
python backend/services/cost_control.py status
```

DeberÃ­as ver:
```
ğŸ†“ Modelos Gratuitos:
  â€¢ gemini: 0 usos

ğŸ’° Modelos Pagos:
  ğŸ”’ anthropic: 0 usos (BLOQUEADO)
  ğŸ”’ openai: 0 usos (BLOQUEADO)
```

### 3. Usar normalmente:
Todo funciona con Gemini (gratis), sin costos.

### 4. Si necesitas modelos pagos:
```powershell
# Habilitar por 1 hora
python backend/services/cost_control.py enable 60
```

---

## ğŸ“ EJEMPLO PRÃCTICO

### Escenario: Quieres comparar respuestas de diferentes modelos

```powershell
# 1. Pregunta con Gemini (gratis, default)
# En el chat: "ExplÃ­came X"
# Respuesta de Gemini 2.0

# 2. Ahora quieres comparar con GPT-4
python backend/services/cost_control.py enable 10  # Solo 10 min

# 3. Forzar que use GPT-4 (temporalmente deshabilitar Gemini)
# O simplemente esperar a que Gemini falle por cuota

# 4. En el chat: "ExplÃ­came X" (misma pregunta)
# ğŸ’° ADVERTENCIA: Usando GPT-4 Turbo - Genera costos
# Respuesta de GPT-4

# 5. Comparas ambas respuestas

# 6. DespuÃ©s de 10 min â†’ GPT-4 se bloquea automÃ¡ticamente
python backend/services/cost_control.py status
# ğŸ”’ openai: 1 uso, $0.02
```

---

## âš ï¸ LIMITACIONES ACTUALES

1. **Auto-deshabilitado no implementado aÃºn**
   - Tienes que deshabilitar manualmente con `disable`
   - TODO: Implementar tarea programada

2. **EstimaciÃ³n de costos aproximada**
   - Se calcula basado en tokens promedio
   - No es 100% exacto

3. **Sin lÃ­mite de gasto estricto**
   - Puedes gastar mÃ¡s del "mÃ¡ximo" si habilitas varias veces
   - TODO: Implementar lÃ­mite acumulado mensual

---

**Estado Actual:** ğŸ“‹ DOCUMENTADO - âœ… INTEGRADO EN ANÃLISIS DEL COACH  
**PrÃ³ximo Paso:** Extender fallback al chat en `AIService.py`
