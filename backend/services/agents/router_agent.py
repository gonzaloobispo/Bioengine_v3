from .base_agent import BaseAgent
from .agent_registry import AgentRegistry
from typing import Dict, Any, Optional, List
import logging

logger = logging.getLogger(__name__)

class RouterAgent:
    """
    Orquestador principal de BioEngine V4.
    Decide qu√© agente especialista debe responder bas√°ndose en el contenido
    de la consulta y el contexto del usuario (System 2 Dispatching).
    """
    
    def __init__(self, registry: AgentRegistry, model_client=None):
        self.registry = registry
        self.model_client = model_client

    async def route(self, query: str, context: Dict[str, Any], chat_history: Optional[List[dict]] = None) -> Dict[str, Any]:
        """
        Analiza la consulta y la deriva al mejor agente disponible.
        """
        logger.info(f"üö¶ Routing query: {query[:50]}...")
        
        # 1. Obtener puntuaciones de todos los agentes
        scores = {}
        agents = self.registry.get_all()
        
        for name, agent in agents.items():
            score = await agent.can_handle(query, context)
            scores[name] = score
            
        # 2. Seleccionar el mejor agente
        best_agent_name = max(scores, key=scores.get)
        best_score = scores[best_agent_name]
        
        # 3. Si la confianza es baja (< 0.4), el coach es el agente default
        if best_score < 0.4:
            logger.warning(f"‚ö†Ô∏è Baja confianza ({best_score}) para {best_agent_name}. Usando Coach por defecto.")
            best_agent_name = "coach"
            
        selected_agent = self.registry.get_agent(best_agent_name)
        
        # 4. Procesar con el agente seleccionado
        response = await selected_agent.process(query, context, chat_history)
        
        # 5. A√±adir metadatos de enrutamiento (Est√°ndar V4)
        response["_router"] = {
            "selected_agent": best_agent_name,
            "confidence": best_score,
            "alternatives": scores
        }
        
        return response

    async def classify_intent_llm(self, query: str) -> str:
        """
        Usa el LLM para una clasificaci√≥n de intenci√≥n m√°s t√©cnica si el 
        enrutamiento basado en keywords falla (System 2 Dispatch).
        """
        if not self.model_client:
            return "coach" # Fallback
            
        prompt = f"""Clasifica la intenci√≥n de esta consulta de un atleta:
Consulta: "{query}"

Categor√≠as:
- recovery: Dolor, lesiones, rehabilitaci√≥n.
- biomechanics: T√©cnica, video, postura.
- coach: Rendimiento, planes, nutrici√≥n.

Responde solo con el nombre de la categor√≠a."""

        # En una implementaci√≥n real, aqu√≠ llamar√≠amos al modelo
        return "coach"
